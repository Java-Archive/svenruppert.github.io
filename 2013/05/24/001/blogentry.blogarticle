<p>In diesem Abschnitt möchte ich den Teil beschreiben, der die Informationen aus den jeweiligen Verzeichnissen holen wird.</p> <p>Im Prinziep handelt es sich um einen minmalen Crawler. Beginnend mit einer Liste von Verzeichnissen, wird rekursiv abgestiegen und die Information aus den jeweiligen Dateien extrahiert. Da es sich um Photos handelt, sind natürlich die EXIF Informationen von Interesse.</p> <p>Hier verwende ich die LIB:&nbsp; <a href="http://drewnoakes.com/code/exif/" target="_blank">com.drewnoakes metadata-extractor 2.6.2</a></p> <p></version>Der Crawler besteht aus den Hauptkomponenten</p> <p>- Node: Hier werden die Informationen gespeichert, jeweils ein Node pro Verzeichnisknoten. File/Dir</p> <p>- Crawler: In diesem Beispiel ein Filesystemcrawler, könnte erweitert werden um andere Quellen-Crawler</p> <p>- FileExtractor: Zum extrahieren der jeweiligen Information jeweils ein spezieller Extractor.</p> <p>Dieses wird noch erweitert um Actions, die dann nach einem Extratordurchlauf pro Node gestartet werden kann.</p> <p>&nbsp;</p> <p>Funktion:</p> <p>Der Crawler bekommt einen Startpunkt und beginnt dort mit dem rekursiven Abstieg. Auf jeden Knoten werden die eine Liste Extraktoren angewendet. Die Informationen in die Attributliste des Node gespeichert. Ein NoteAttribute ist eine einfache Key/Value Kombination.</p> <p>UML-Bild: (im Repository unter data/uml zu finden)</p> <p><a href="http://lh3.ggpht.com/-gLUI8ilM8XE/UZ_Di5F8TPI/AAAAAAABQ10/ZdzmwDPq4iE/s1600-h/image%25255B5%25255D.png" target="_blank"><img title="image" style="border-left-width: 0px; border-right-width: 0px; border-bottom-width: 0px; display: inline; border-top-width: 0px" border="0" alt="image" src="http://lh5.ggpht.com/-hTqkoMiYGUY/UZ_Dj0K-gYI/AAAAAAABQ18/g_dfNwhbN8s/image_thumb%25255B3%25255D.png?imgmax=800" width="658" height="460"></a> </p> <p>&nbsp;</p> <p>&nbsp;<br></p><pre class="brush: Xml">         </dependency><br /></pre>  